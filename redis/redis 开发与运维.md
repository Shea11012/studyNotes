Redis 采用单线程架构和 I/O 多路复用模型来实现高性能的内存数据库。

Redis 使用单线程还处理速度快：

1. 纯内存访问，Redis 将数据放在内存中，内存响应时间短。
2. 非阻塞 I/O，Redis 使用 epoll 模型，加上 Redis 自身的事件处理模型将 epoll 中的连接、读写、关闭都转换为事件，不会在网络 I/O 上浪费过多的时间。
3. 单线程避免了线程切换和竞态产生的消耗。

Redis 的对外数据结构有：

- string，内部编码：

  - int：8 个字节的长整型
  - embstr：小于等于 39 个字节的字符串
  - raw：大于 39 个字节的字符串

  使用场景：

  1. 缓存功能，由于 Redis 具有支撑高并发的特性，缓存通常能起到加速读写和降低后端压力的作用
  2. 计数
  3. 共享 session
  4. 限速

- hash，内部编码：

  - ziplist（压缩列表）：当哈希类型元素个数小于 hash-max-ziplist-entries 配置（默认 512 个），同时所有值都小于 hash-max-ziplist-value 时（默认 64 字节），Redis 会使用 ziplist 作为哈希的内部实现，ziplist 使用更加紧凑的结构实现多个元素的连续存储，所以在节省内存方面比 hashtable 好。
  - hashtable（哈希表）：当哈希类型无法满足 ziplist 条件时，Redis 会使用 hashtable，因为此时 ziplist 的读写效率会下降。

- list，内部编码：

  - ziplist
  - linkedlist，当 ziplist 的条件无法满足时，会使用 linkedlist

  使用场景：

  1. 消息队列，lpush + brpop 可实现阻塞队列，生产者使用 lpush 从列表左侧插入元素，多个消费者使用 brpop 命令阻塞式抢列表尾部元素

  lpush + lpop = stack

  lpush + rpop = queue

  lpush + ltrim = capped collection （有限集合）

  lpush + brpop = message queue （消息队列）

- set，内部编码：

  - intset（整数集合）：当集合中的元素都是整数且元素个数小于 set-max-intset-entries（默认 512 个）
  - hastable：当无法满足 intset 的条件时

  使用场景：

  1. 标签，如：给用户贴上标签，根据标签计算交集并集合集，**用户和标签的关系应该在一个事务内执行，防止部分命令失败**
  2. 随机数：利用集合无序性

- zset，内部编码：

  - ziplist：当有序集合的元素个数小于 zset-max-ziplist-entries（默认 128 个），每个元素值都小于 zset-max-ziplist-value（默认 64 字节）
  - skiplist（跳跃表）：当 ziplist 条件不满足时

  使用场景：

  1. 排行榜

Redis 的每种数据结构都包含两种以上内部编码实现，可以通过 `object encoding` 查询内部编码，Redis 会根据不同的场景实现内部数据结构转换。

### redis 命令使用注意

`get` 和 `mget` 的区别，在与一个是单次命令一个是批处理，使用适当的批处理，有助于提高业务的处理效率，如果批处理的命令数过多可能造成 Redis 阻塞或网络拥塞。

`hgetall` ，如果哈希元素个数比较多，有可能阻塞 Redis，如果只需要获取部分 field，可以使用 `hmget`，如果需要获取全部 field-value，可以使用 `hscan` 该命令会渐进式遍历哈希类型。

### 慢查询

Redis 使用一个列表来存储慢查询日志，超出了日志长度会删除头部的日志。

慢查询只记录命令执行时间，并不包括命令排队和网络传输时间。因此客户端执行命令的时间会大于命令实际执行时间。因为命令排队机制，慢查询会导致其它命令级联阻塞，所以在客户端出现请求超时，**需要检查该时间点是否有对应的慢查询，从而分析出是否为慢查询导致的命令级联阻塞。**

慢查询配置参数：

- slowlog-log-slower-tha：预设阀值，单位微妙，默认 10000
- slowlog-max-len：慢查询日志最多存储条数

### 事务与 lua

`multi` 代表事务开始，`exec` 代表事务结束，`discard` 取消事务执行

### bitmaps

可以用来记录用户的登录，如果每天的活跃用户都很多的情况下可以使用 bitmap 会比使用集合类型要节省内存，但如果每天的访问用户量很少的情况下，可以使用集合

### HyperLogLog

HyperLogLog 可以利用极小的内存空间完成独立总数的统计。

HyperLogLog 内存占用量非常小，但是存在错误率（0.81%），在可以容忍一定误差率的时可以使用HyperLogLog

### 持久化

Redis 持久化分为两种：AOF 和 RDB

#### RDB

RDB 持久化是把当前进程数据生成快照保存到硬盘的过程，触发 RDB 持久化过程分为手动触发和自动触发。

**手动触发分别对应 save 和 bgsave 命令**

- save：阻塞当前 redis 服务器，知道 RDB 过程完成
- bgsave：redis 进程执行 fork 操作创建子进程，RDB 持久化过程由子进程负责，完成后自动结束。阻塞只发生在 fork 阶段。

除了手动触发，redis 内部的自动触发机制，如下：

1. 使用 save 配置，`save m n` 表示 m 秒内数据集存在 n 次修改，自动触发 bgsave
2. 如果从节点执行全量复制操作，主节点自动执行 bgsave 生成 RDB 文件并发送给从节点
3. 执行 `debug reload` 命令重新加载 redis
4. 默认情况下执行 `shutdown` ，如果没有开启 AOF 持久化则自动执行 bgsave

**优点：**

> RDB 是一个紧凑压缩的二进制文件，代表 Redis 在某个时间点上的数据快照。适用备份，全量复制等场景。如每 6 小时执行 bgsave 备份并把 RDB 文件拷贝到远程机器或者文件系统中，用于灾难恢复。
>
> RDB 加载速度快于 AOF。

**缺点：**

> RDB 没有办法做到实时持久化、秒级持久化。因为 bgsave 每次运行都要执行 fork 操作创建子进程，属于重量级操作，频繁执行成本过高。
>
> RDB 使用特定二进制格式保存，会存在老版本服务无法兼容新版本的问题。

#### AOF

AOF 持久化，以独立日志的方式记录每次写命令，重启时在重新执行 AOF 文件中的命令达到恢复数据的目的。AOF 的主要作用是解决数据持久化的实时性。

AOF 默认不开启，设置配置 `appendonly yes`

AOF 命令写入的内容是文本协议格式。

AOF 缓冲区同步文件策略，由参数 `appendfsync` 控制：

- always：命令写入 aof_buf 后调用系统 fsync 操作同步到 AOF 文件，fsync 完成后线程返回
- everysec：命令写入 aof_buf 后调用系统 write 操作，write 完成后线程返回。fsync 同步文件操作由专门线程每秒调用一次。
- no：命令写入 aof_buf 后调用系统 write 操作，不对 AOF 文件做 fsync 同步，同步硬盘操作由操作系统负责，同步周期最长 30 秒

AOF 重写机制：

1. 进程内已经超时的数据不再写入文件
2. 旧的 AOF 文件含有无效命令，如 del key1、hdel key2 等。重写使用进程内数据直接生成，这样新的 AOF 文件只保留最终数据的写入命令。
3. 多条写入命令可以合并为一个。为了防止单条命令过大造成客户端缓冲区溢出，对于 list、set、hash 等类型操作，以 64 个元素为界拆分为多条。

AOF 重写可以手动和自动触发：

- 手动触发：调用 `bgrewriteaof`
- 自动触发，配置参数：
  - `auto-aof-rewrite-min-size`：运行 AOF 重写是文件最小体积，默认 64MB 
  -  `auto-aof-rewrite-percentage` ：代表当前 AOF 文件空间 aof_current_size 和上一次重写后 AOF 文件空间 aof_base_size 的比值。

### 复制

配置复制的方式：

1. 在配置文件中加入 `slaveof {masterHost} {masterPort}`
2. 在 redis-server 启动命令加入参数 `--slaveof {masterHost} {masterPort}`
3. 使用命令 `slaveof {masterHost} {masterPort}`

#### 拓扑：

1. 一主一从：用于主节点出现宕机时从节点提供故障转移支持。当应用写命令并发量较高且需要持久化时，可以只在从节点上开启 AOF，这样既保证数据安全性同时也避免了持久化对主节点的性能干扰。**如果主节点没有开启持久化功能，自动重启后数据集为空，这时从节点如果继续复制主节点会导致从节点数据也被清空，丧失持久化意义。<font color="red">安全的做法是从节点上执行 slaveof no one 断开与主节点的复制关系，再重启主节点。</font>**

2. 一主多从：利用多个从节点实现读写分离。对于读占比大的场景，可以把读命令发送到从节点来分担主节点压力。同时如果需要执行一些耗时操作时，可以在其中一台从节点上执行，防止慢查询对主节点造成阻塞从而影响线上服务的稳定性。缺点：对于写并发高的场景，多个从节点会导致主节点写命令的多次发送从而过度消耗网络带宽，同时也增加了主节点的负载影响服务稳定性。
3. 树状主从结构：从节点不但可以复制主节点数据，同时还可以作为其他从节点的主节点继续向下复制。<font color="blue">通过引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数据量。</font><font color="red">当主节点需要挂载多个从节点时为了避免对主节点的性能干扰，可以采用树状主从结构降低主节点压力。</font>

### 内存

#### redis 内存回收策略

1. 删除过期键对象
   - 惰性删除：当客户端读取带有超时属性的键时，如果已经超过键设置的过期时间，会执行删除操作并返回空。优点是节省 CPU 成本，不需要单独维护 TTL 链表来处理过期键的删除。缺点是存在内存泄漏问题，当过期键一直没有访问将无法得到及时删除，从而导致内存不能及时释放。
   - 定时任务删除：Redis 内部维护一个定时任务，默认每秒运行 10 次。该逻辑采用了自适应算法，根据键的过期比例、使用快慢两种速率模式回收键
2. 内存溢出控制策略：
   - noeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息，此时只会响应读操作。
   - volatile-lru：根据 LRU 算法删除设置了超时属性的键，知道腾出足够空间为止，如果没有可删除的键对象，回退到 noeviction 策略。
   - allkeys-lru：根据 LRU 算法删除键，不管数据有没有设置超时属性，知道腾出足够空间为止。
   - allkeys-random：随机删除所有键，直到腾出足够空间为止。
   - volatile-random：随机删除过期键，直到腾出足够空间为止。
   - volatile-ttl：根据键值对象的 ttl 属性，删除最近将要过期数据。如果没有，回退到 noeviction 策略。

### redis 缓存设计

#### 缓存更新策略

1. LRU、LFU、FIFO 淘汰算法，在 redis 中只需配置 maxmemory 和选择对应的算法。数据的一致性最差
2. 超时淘汰，在过期时间内可能存在数据不一致
3. 主动更新，一致性最高，可以结合超时淘汰（有可能有些数据会长时间不被更新）

低一致性业务可以使用最大内存和淘汰策略

高一致性业务可以结合超时淘汰和主动更新，这样即使主动更新出了问题，也能保证数据过期时间后删除脏数据。

#### 穿透优化

缓存穿透是指一个根本不存在的数据，缓存层和存储层都不会命中，通常出于容错考虑，如果存储层查不到数据则不写入缓存层。

解决办法：

1. **缓存空对象**：针对这类数据设置一个较短的过期时间。为了避免缓存层和存储层的数据会有一段时间的不一致，如：给空对象设置了过期时间为 5 分钟，如果此存储层此时添加了这个数据，那么此段时间的数据不一致，可以利用消息系统或者其他方法清除掉缓存层中的空对象。

适用场景：数据命中不高，数据频繁变化实时性高

1. **布隆过滤器**：在访问缓存层和存储层之前，将存在的 key 用布隆过滤器提前保存，如果布隆过滤器认为该用户不存在则不会访问存储层。

适用场景：数据命中不高，数据相对固定实时性低

#### 无底洞优化

问题：在一个有着 3000 个节点的集群中，因为性能问题而继续添加节点，却发现性能不但没有好转反而下降。

原因：键值数据库通常采用哈希函数将 key 映射到各个节点上，由于数据量好访问量的持续增长，需要添加大量节点做水平扩容，导致键值分布到更多节点上。无论 memcache 还是 redis 的分布式，批量操作通常需要从不同节点上获取，相比于单机批量操作只涉及一次网络操作，分布式批量操作会涉及多次网络时间。**客户端一次批量操作会涉及多次网络操作，意味着批量操作会随着节点的增多，耗时会不断增大。网络连接数变多，对节点的性能也有一定影响。**

解决方法：

1. 串行命令，获取 n 个key 的值逐次执行 n 个 get 的命令，时间复杂度 = n次网络时间+n 次命令时间
2. 串行 IO：根据 redis 计算插槽的方法，手动计算（CRC16 计算散列值，再对 16384 取余），根据这个数据将同一个节点的 key 归档，之后再对个每个节点执行 mget 或者 pipeline 操作。时间复杂度=node 次网络时间+n 次命令时间。
3. 并行 IO：将串行 IO 改为多线程执行。
4. hash_tag：将多个 key 强制分配到一个节点上

#### 雪崩优化

缓存雪崩：由于缓存层承载着大量请求，有效的保护了存储层，但如果缓存层由于某些原因不能提供服务，于是所有的请求都会到达存储层，存储层的调用量会暴增，造成存储层也会级联宕机。

解决方法：

1. 保证缓存层服务高可用
2. 依赖隔离组件为后端限流并降级

#### 热点 key 重建优化

缓存+过期时间的策略可以加速数据读写，又保证数据的定期更新，但会有两个问题如果同时出现，可能会对应用造成致命的危害：

- 当前 key 是一个热点 key，并发量非常大
- 重建缓存不能再短时间完成，可能是一个复杂的计算

缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，可能会让应用崩溃。

解决办法：

1. 互斥锁：此方法只允许一个线程重建缓存，其它线程等待重建缓存的线程执行完，重新从缓存获取数据。
2. 永不过期：从缓存层不设置过期时间，在代码层为每个 value 设置一个逻辑过期时间，当发现超过逻辑过期时间后，重建缓存。